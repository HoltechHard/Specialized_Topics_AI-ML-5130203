{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 06: Deep Neural Nets applied to Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case of study 03: Prediction of Fuel Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Metadata  \n",
    "Data study of city-cycle fuel consumption. Next, we have the list of metadata:  \n",
    "  \n",
    "* **mpg**: target. You far can travel one automobile per gallon of fuel\n",
    "* **cylinders**: integer\n",
    "* **displacement**: continuous\n",
    "* **house power**: continuous\n",
    "* **weight**: continuous\n",
    "* **acceleration**: continuous\n",
    "* **model year**: integer\n",
    "* **origin**: categorical [1-US; 2-Europe; 3-Japan]\n",
    "* **car name**: categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metadata: columns name\n",
    "metadata = [\"mpg\", \"cylinders\", \"displacement\", \"house_power\", \"weight\", \"acceleration\", \n",
    "            \"model_year\", \"origin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/auto-mpg.data\", names=metadata, na_values=\"?\", sep=\" \", comment='\\t', skipinitialspace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot missing data\n",
    "sbn.displot(\n",
    "    data = data.isna().melt(value_name=\"missing\"),\n",
    "    y = \"variable\",\n",
    "    hue = \"missing\",\n",
    "    multiple = \"fill\",\n",
    "    aspect = 1.5\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "print(\"#Total samples without missing values = \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "x = data.loc[:, data.columns != \"mpg\"]\n",
    "y = data[\"mpg\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of each subset of data\n",
    "print(\"Dimensions in x-train: \", x_train.shape)\n",
    "print(\"Dimensions in y-train: \", y_train.shape)\n",
    "print(\"Dimensions in x-test: \", x_test.shape)\n",
    "print(\"Dimensions in y-test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math transformations for features\n",
    "transformer = ColumnTransformer(transformers = [\n",
    "    (\"num\", StandardScaler(), [\"cylinders\", \"displacement\", \"house_power\", \"weight\", \"acceleration\", \"model_year\"]),\n",
    "    (\"cat\", OneHotEncoder(), [\"origin\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer will learn only from training data\n",
    "transformer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer will apply in the train and test data\n",
    "x_train = transformer.transform(x_train)\n",
    "x_test = transformer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to Pytorch tensor data structure\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dim x-train tensor: \", x_train_tensor.shape)\n",
    "print(\"y-train tensor: \", y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders with batches of data\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch class to define regressor architecture\n",
    "class RegressionNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, activation_func):\n",
    "        super(RegressionNeuralNet, self).__init__()\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + hidden_layers\n",
    "        self.activation_dict = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh()\n",
    "        }\n",
    "\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(in_features=layer_sizes[i], out_features=layer_sizes[i+1]))\n",
    "            layers.append(self.activation_dict[activation_func])\n",
    "        layers.append(nn.Linear(in_features=layer_sizes[-1], out_features=1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of experiments\n",
    "experiments = [\n",
    "    {'hidden_layers': [32, 16], 'activation': 'relu'},\n",
    "    {'hidden_layers': [64, 32, 16], 'activation': 'relu'},\n",
    "    {'hidden_layers': [32, 16], 'activation': 'sigmoid'},\n",
    "    {'hidden_layers': [64, 32, 16], 'activation': 'sigmoid'},\n",
    "    {'hidden_layers': [32, 16], 'activation': 'tanh'},\n",
    "    {'hidden_layers': [64, 32, 16], 'activation': 'tanh'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training/Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_model(model, train_loader, test_loader, device, num_epochs=200):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # for each iteration\n",
    "    for epoch in range(num_epochs):\n",
    "        # training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_loss += loss.item()\n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(input_size, experiments, train_loader, test_loader, x_test_tensor, device):    \n",
    "\n",
    "    experiment_results = []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        print(f\"Run experiment with hidden layers: {experiment['hidden_layers']}, activation: {experiment['activation']}\")\n",
    "\n",
    "        model = RegressionNeuralNet(input_size=input_size,\n",
    "                                    hidden_layers=experiment['hidden_layers'],\n",
    "                                    activation_func=experiment['activation']).to(device)\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_losses, test_losses = train_model(model, train_loader, test_loader, device)\n",
    "        end_time = time.time()\n",
    "\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # testing        \n",
    "        model.eval()\n",
    "        y_pred = model(x_test_tensor.to(device)).cpu().detach().numpy()\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "        print(f\"R^2: {r2:.4f}\")\n",
    "\n",
    "        experiment_results.append({\n",
    "            'experiment': experiment,\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses,\n",
    "            'mse': mse,\n",
    "            'r2': r2,\n",
    "            'training_time': training_time\n",
    "        })\n",
    "\n",
    "    return experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training/test process\n",
    "exp_results = run_training(x_train.shape[1], experiments, train_loader, test_loader, x_test_tensor, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Monitoring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitoring_results(experiment_results):\n",
    "\n",
    "    # Plotting the results\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(10, 25))\n",
    "\n",
    "    # Plot train and test loss by epoch for each experiment\n",
    "    for result in experiment_results:\n",
    "        experiment = result['experiment']\n",
    "        axes[0].plot(result['train_losses'], label=f\"Train: {experiment['hidden_layers']} layers, {experiment['activation']}\")\n",
    "        axes[1].plot(result['test_losses'], label=f\"Test: {experiment['hidden_layers']} layers, {experiment['activation']}\")\n",
    "    \n",
    "    # training loss report\n",
    "    axes[0].set_title('Training Loss by Epoch')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # test loss report\n",
    "    axes[1].set_title('Testing Loss by Epoch')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "\n",
    "    experiment_labels = [f\"{exp['hidden_layers']} layers, {exp['activation']}\" for exp in experiments]\n",
    "\n",
    "    # Plot Mean Squared Error for each experiment    \n",
    "    mses = [result['mse'] for result in experiment_results]    \n",
    "    axes[2].bar(experiment_labels, mses)\n",
    "    axes[2].set_title('Mean Squared Error by Experiment')\n",
    "    axes[2].set_xlabel('Experiment')\n",
    "    axes[2].set_ylabel('MSE')\n",
    "    axes[2].set_ylim(0, max(mses) + 1)\n",
    "    axes[2].set_xticks(range(len(experiment_labels)))\n",
    "    axes[2].set_xticklabels(experiment_labels, rotation = 45, ha = 'right')    \n",
    "\n",
    "    # por R^2 for each experiment\n",
    "    r2s = [result['r2'] for result in experiment_results]    \n",
    "    axes[3].bar(experiment_labels, r2s)\n",
    "    axes[3].set_title('R^2 by Experiment')\n",
    "    axes[3].set_xlabel('Experiment')\n",
    "    axes[3].set_ylabel('R^2')\n",
    "    axes[3].set_ylim(0, 1)\n",
    "    axes[3].set_xticks(range(len(experiment_labels)))\n",
    "    axes[3].set_xticklabels(experiment_labels, rotation = 45, ha = 'right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_results(exp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
