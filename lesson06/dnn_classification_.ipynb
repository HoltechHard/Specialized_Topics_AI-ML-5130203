{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 06: Deep Neural Nets applied to Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case of study 04: Breast Cancer Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Metadata  \n",
    "\n",
    "* **data**: This is a 2D array (matrix) containing the features of the dataset. Each row corresponds to a sample (tumor), and each column corresponds to a feature (measurement).  \n",
    "* **target**: This is a 1D array containing the labels for each sample. The labels indicate whether the tumor is malignant (1) or benign (0).   \n",
    "* **feature_names**: This is a list of strings representing the names of the features in the dataset.   \n",
    "* **target_names**: This is a list of strings representing the names of the target classes. In this case, it indicates the two classes: malignant and benign.  \n",
    "* **DESCR**: This is a string containing a detailed description of the dataset, including information about how it was collected, its purpose, and any relevant notes.  \n",
    "* **filename**: This is a string that indicates the path to the dataset file  \n",
    "* **data_module**: This field indicates the source of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names\n",
    "metadata = data.feature_names\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split independent and dependent variables\n",
    "x = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of each subset of data\n",
    "print(\"Dimensions in x-train: \", x_train.shape)\n",
    "print(\"Dimensions in y-train: \", y_train.shape)\n",
    "print(\"Dimensions in x-test: \", x_test.shape)\n",
    "print(\"Dimensions in y-test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer will learn only from training data\n",
    "transformer = StandardScaler()\n",
    "transformer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer will apply in the train and test data\n",
    "x_train = transformer.transform(x_train)\n",
    "x_test = transformer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to Pytorch tensor data structure\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dim x-train tensor: \", x_train_tensor.shape)\n",
    "print(\"y-train tensor: \", y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders with batches of data\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class ClassifierNeuralNet(nn.Module):\n",
    "    def __init__(self, input_neurons, output_neurons, num_hidden_layers, hidden_neurons_x_layer, activation):\n",
    "        super(ClassifierNeuralNet, self).__init__()\n",
    "        # input layer definition\n",
    "        layers = [nn.Linear(input_neurons, hidden_neurons_x_layer[0])]\n",
    "        # hidden layers definition\n",
    "        for i in range(1, num_hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_neurons_x_layer[i-1], hidden_neurons_x_layer[i]))\n",
    "            if activation == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            elif activation == 'sigmoid':\n",
    "                layers.append(nn.Sigmoid())\n",
    "        # output layer definition\n",
    "        layers.append(nn.Linear(hidden_neurons_x_layer[-1], output_neurons))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        # model architecture definition\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    # forward step\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of experiments\n",
    "experiments = [\n",
    "    {'num_layers': 2, 'neurons_per_layer': [16, 8], 'activation': 'relu'},\n",
    "    {'num_layers': 3, 'neurons_per_layer': [32, 16, 8], 'activation': 'relu'},\n",
    "    {'num_layers': 2, 'neurons_per_layer': [16, 8], 'activation': 'tanh'},\n",
    "    {'num_layers': 3, 'neurons_per_layer': [32, 16, 8], 'activation': 'tanh'},\n",
    "    {'num_layers': 2, 'neurons_per_layer': [16, 8], 'activation': 'sigmoid'},\n",
    "    {'num_layers': 3, 'neurons_per_layer': [32, 16, 8], 'activation': 'sigmoid'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train/test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function for classification\n",
    "def train_model(model, train_loader, device, num_epochs):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to run the training and evaluation process\n",
    "def run_training(input_size, experiments, train_loader, x_test_tensor, y_test, device, num_epochs = 100):\n",
    "    experiment_results = []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        print(f\"Run experiment with hidden layers: {experiment['neurons_per_layer']}, activation: {experiment['activation']}\")\n",
    "\n",
    "        model = ClassifierNeuralNet(input_neurons=input_size,\n",
    "                                     output_neurons=1,\n",
    "                                     num_hidden_layers=experiment['num_layers'],\n",
    "                                     hidden_neurons_x_layer=experiment['neurons_per_layer'],\n",
    "                                     activation=experiment['activation']).to(device)\n",
    "\n",
    "        start_time = time.time()\n",
    "        trained_model = train_model(model, train_loader, device, num_epochs)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Testing\n",
    "        trained_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_probs = trained_model(x_test_tensor.to(device)).cpu().numpy()\n",
    "            y_pred = (y_pred_probs > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        experiment_results.append({\n",
    "            'experiment': experiment,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'training_time': end_time - start_time\n",
    "        })\n",
    "\n",
    "    return experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute training experiment\n",
    "exp_results = run_training(input_size=30, experiments=experiments, train_loader=train_loader,\n",
    "                           x_test_tensor=x_test_tensor, y_test=y_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Monitoring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data for plotting\n",
    "def monitoring_results(exp_results):\n",
    "    # define the list of metrics\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'training_time']\n",
    "    data = {\n",
    "        'experiment': [],\n",
    "        'metric': [],\n",
    "        'value': []\n",
    "    }\n",
    "\n",
    "    # re-structure the json data to dataframe\n",
    "    for idx, result in enumerate(exp_results):\n",
    "        for metric in metrics:\n",
    "            data['experiment'].append(f\"Experiment {idx + 1}\")\n",
    "            data['metric'].append(metric)\n",
    "            data['value'].append(result[metric])\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    plt.figure(figsize=(10, 14))\n",
    "\n",
    "    # Create a bar plot\n",
    "    for metric in metrics:\n",
    "        # plot the bars comparison of metrics for each experiment\n",
    "        ax = plt.subplot(3, 2, metrics.index(metric) + 1)\n",
    "        bar_plot = sbn.barplot(x='experiment', y='value', data=df[df['metric'] == metric], \n",
    "                    hue='experiment', palette='viridis', legend=False)\n",
    "        plt.title(metric.capitalize())\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.ylim(0, 1.1 if metric != 'training_time' else None)\n",
    "\n",
    "        # Annotate each bar with the respective value\n",
    "        for p in bar_plot.patches:\n",
    "            ax.annotate(f'{p.get_height():.3f}', \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='bottom', fontsize=10, color='black', \n",
    "                        xytext=(0, 5), textcoords='offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_results(exp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
